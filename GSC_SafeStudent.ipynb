{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10629fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and seeds for reproducibility\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as f:\n",
    "                return [os.path.join(self._path, line.strip()) for line in f]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "            \n",
    "        print(f\"Loaded {subset} set with {len(self._walker)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda73ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_set = SubsetSC(\"training\")\n",
    "val_set = SubsetSC(\"validation\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "\n",
    "# Get list of labels\n",
    "labels = sorted(list(set(item[2] for item in train_set)))\n",
    "label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "index_to_label = {i: label for i, label in enumerate(labels)}\n",
    "\n",
    "print(f\"Number of classes: {len(labels)}\")\n",
    "print(f\"Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio preprocessing\n",
    "class AudioPreprocessor:\n",
    "    def __init__(self, sample_rate=16000, n_mfcc=40, n_fft=400, hop_length=160):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        \n",
    "        # MFCC transform\n",
    "        self.mfcc_transform = T.MFCC(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mfcc=n_mfcc,\n",
    "            melkwargs={\n",
    "                'n_fft': n_fft,\n",
    "                'hop_length': hop_length,\n",
    "                'n_mels': 80,\n",
    "                'center': False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    def __call__(self, waveform, sample_rate):\n",
    "        # Resample if needed\n",
    "        if sample_rate != self.sample_rate:\n",
    "            resampler = T.Resample(orig_freq=sample_rate, new_freq=self.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "            \n",
    "        # Convert to mono if stereo\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "        # Pad or trim to 1 second (16000 samples)\n",
    "        if waveform.shape[1] < self.sample_rate:\n",
    "            waveform = F.pad(waveform, (0, self.sample_rate - waveform.shape[1]))\n",
    "        else:\n",
    "            waveform = waveform[:, :self.sample_rate]\n",
    "            \n",
    "        # Extract MFCC features\n",
    "        mfcc = self.mfcc_transform(waveform)\n",
    "        \n",
    "        # Check for NaN or Inf values\n",
    "        if torch.isnan(mfcc).any() or torch.isinf(mfcc).any():\n",
    "            mfcc = torch.nan_to_num(mfcc, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "            \n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ee429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "class AudioAugmentation:\n",
    "    def __init__(self):\n",
    "        self.time_mask = T.TimeMasking(time_mask_param=10)\n",
    "        self.freq_mask = T.FrequencyMasking(freq_mask_param=10)\n",
    "        \n",
    "    def augment(self, x, strength=1.0):\n",
    "        # Apply augmentation based on strength\n",
    "        if strength > 0.5:\n",
    "            x = self.freq_mask(x)\n",
    "        if strength > 0.7:\n",
    "            x = self.time_mask(x)\n",
    "        if strength > 0.3:\n",
    "            # Add some noise\n",
    "            noise = torch.randn_like(x) * (0.1 * strength)\n",
    "            x = x + noise\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset for semi-supervised learning\n",
    "class SpeechCommandDataset(Dataset):\n",
    "    def __init__(self, dataset, preprocessor, label_to_index):\n",
    "        self.dataset = dataset\n",
    "        self.preprocessor = preprocessor\n",
    "        self.label_to_index = label_to_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sample_rate, label, _, _ = self.dataset[idx]\n",
    "        \n",
    "        # Preprocess audio\n",
    "        features = self.preprocessor(waveform, sample_rate)\n",
    "        \n",
    "        # Convert label to index\n",
    "        label_idx = self.label_to_index[label]\n",
    "        \n",
    "        return features, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = AudioPreprocessor()\n",
    "\n",
    "# Create datasets with preprocessing\n",
    "train_dataset = SpeechCommandDataset(train_set, preprocessor, label_to_index)\n",
    "val_dataset = SpeechCommandDataset(val_set, preprocessor, label_to_index)\n",
    "test_dataset = SpeechCommandDataset(test_set, preprocessor, label_to_index)\n",
    "\n",
    "# Split training set into labeled and unlabeled\n",
    "num_labeled = 1000  # Number of labeled examples to use\n",
    "total_samples = len(train_dataset)\n",
    "\n",
    "# Create indices for the split\n",
    "indices = list(range(total_samples))\n",
    "random.shuffle(indices)\n",
    "labeled_indices = indices[:num_labeled]\n",
    "unlabeled_indices = indices[num_labeled:]\n",
    "\n",
    "# Create labeled and unlabeled datasets\n",
    "labeled_dataset = Subset(train_dataset, labeled_indices)\n",
    "unlabeled_dataset = Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "print(f\"Labeled samples: {len(labeled_dataset)}\")\n",
    "print(f\"Unlabeled samples: {len(unlabeled_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2eda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 64\n",
    "labeled_batch_size = 16  # Per batch\n",
    "\n",
    "labeled_loader = DataLoader(\n",
    "    labeled_dataset,\n",
    "    batch_size=labeled_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=batch_size - labeled_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Check a batch from each loader to verify shapes\n",
    "for name, loader in [(\"Labeled\", labeled_loader), (\"Unlabeled\", unlabeled_loader), (\"Val\", val_loader)]:\n",
    "    inputs, labels = next(iter(loader))\n",
    "    print(f\"{name} batch - inputs: {inputs.shape}, labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Pooling and dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Note: The exact size will depend on your input dimensions\n",
    "        # We'll calculate this dynamically in the forward pass\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 512)  # This will be adjusted in forward pass\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.fc_input_size = None  # Will be set in first forward pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch, channels, height, width]\n",
    "        # For MFCC: [batch, 1, n_mfcc, time]\n",
    "        \n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Dynamically compute the flattened size on first run\n",
    "        if self.fc_input_size is None:\n",
    "            self.fc_input_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            # Recreate fc1 with the correct input size\n",
    "            self.fc1 = nn.Linear(self.fc_input_size, 512).to(x.device)\n",
    "            print(f\"Set fc_input_size to {self.fc_input_size}\")\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "student_model = AudioCNN(num_classes=len(labels)).to(device)\n",
    "teacher_model = deepcopy(student_model)\n",
    "\n",
    "# Set teacher model to evaluation mode\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe Student training function\n",
    "class SafeStudent:\n",
    "    def __init__(self, student_model, teacher_model, num_classes, \n",
    "                 alpha=0.99, temperature=0.5, lambda_consistency=1.0):\n",
    "        self.student_model = student_model\n",
    "        self.teacher_model = teacher_model\n",
    "        self.num_classes = num_classes\n",
    "        self.alpha = alpha  # EMA decay rate\n",
    "        self.temperature = temperature  # Temperature for soft targets\n",
    "        self.lambda_consistency = lambda_consistency  # Weight for consistency loss\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(student_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=100)\n",
    "        self.augmentation = AudioAugmentation()\n",
    "        \n",
    "    def update_teacher(self):\n",
    "        # Update teacher model using exponential moving average\n",
    "        for teacher_param, student_param in zip(self.teacher_model.parameters(), \n",
    "                                               self.student_model.parameters()):\n",
    "            teacher_param.data.mul_(self.alpha).add_(student_param.data, alpha=1 - self.alpha)\n",
    "    \n",
    "    def consistency_loss(self, logits_s, logits_t):\n",
    "        # KL divergence between student and teacher predictions\n",
    "        p_s = F.log_softmax(logits_s / self.temperature, dim=1)\n",
    "        p_t = F.softmax(logits_t / self.temperature, dim=1)\n",
    "        return F.kl_div(p_s, p_t, reduction='batchmean') * (self.temperature ** 2)\n",
    "    \n",
    "    def train_epoch(self, labeled_loader, unlabeled_loader, epoch):\n",
    "        self.student_model.train()\n",
    "        self.teacher_model.eval()  # Teacher always in eval mode\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        total_sup_loss = 0.0\n",
    "        total_unsup_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Create iterators for the loaders\n",
    "        labeled_iter = iter(labeled_loader)\n",
    "        unlabeled_iter = iter(unlabeled_loader)\n",
    "        \n",
    "        # Determine number of batches\n",
    "        num_batches = min(len(labeled_loader), len(unlabeled_loader))\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for batch_idx in pbar:\n",
    "            # Get labeled batch\n",
    "            try:\n",
    "                inputs_x, targets_x = next(labeled_iter)\n",
    "            except StopIteration:\n",
    "                labeled_iter = iter(labeled_loader)\n",
    "                inputs_x, targets_x = next(labeled_iter)\n",
    "            \n",
    "            # Get unlabeled batch\n",
    "            try:\n",
    "                inputs_u, _ = next(unlabeled_iter)\n",
    "            except StopIteration:\n",
    "                unlabeled_iter = iter(unlabeled_loader)\n",
    "                inputs_u, _ = next(unlabeled_iter)\n",
    "            \n",
    "            # Move to device\n",
    "            inputs_x, targets_x = inputs_x.to(device), targets_x.to(device)\n",
    "            inputs_u = inputs_u.to(device)\n",
    "            \n",
    "            # Apply augmentation to unlabeled data\n",
    "            inputs_u_aug = torch.stack([self.augmentation.augment(x.unsqueeze(0), strength=0.8).squeeze(0) \n",
    "                                       for x in inputs_u])\n",
    "            \n",
    "            # Forward pass through student model\n",
    "            logits_x = self.student_model(inputs_x)  # Labeled data\n",
    "            logits_u_aug = self.student_model(inputs_u_aug)  # Augmented unlabeled data\n",
    "            \n",
    "            # Supervised loss\n",
    "            loss_x = self.criterion(logits_x, targets_x)\n",
    "            \n",
    "            # Get teacher predictions for unlabeled data (without augmentation)\n",
    "            with torch.no_grad():\n",
    "                logits_u_teacher = self.teacher_model(inputs_u)\n",
    "            \n",
    "            # Consistency loss between student and teacher\n",
    "            loss_u = self.consistency_loss(logits_u_aug, logits_u_teacher)\n",
    "            \n",
    "            # Total loss\n",
    "            loss = loss_x + self.lambda_consistency * loss_u\n",
    "            \n",
    "            # Check for NaN loss\n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN loss detected!\")\n",
    "                print(f\"loss_x: {loss_x}, loss_u: {loss_u}\")\n",
    "                # Skip this batch\n",
    "                continue\n",
    "            \n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(self.student_model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Update teacher model with EMA\n",
    "            self.update_teacher()\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item()\n",
    "            total_sup_loss += loss_x.item()\n",
    "            total_unsup_loss += loss_u.item()\n",
    "            \n",
    "            # Calculate accuracy for supervised data\n",
    "            _, predicted = torch.max(logits_x, 1)\n",
    "            total += targets_x.size(0)\n",
    "            correct += (predicted == targets_x).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'sup_loss': f\"{loss_x.item():.4f}\",\n",
    "                'unsup_loss': f\"{loss_u.item():.4f}\",\n",
    "                'acc': f\"{100 * correct / total:.2f}%\"\n",
    "            })\n",
    "        \n",
    "        # Update learning rate\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        avg_sup_loss = total_sup_loss / num_batches\n",
    "        avg_unsup_loss = total_unsup_loss / num_batches\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        return avg_loss, avg_sup_loss, avg_unsup_loss, accuracy\n",
    "    \n",
    "    def evaluate(self, test_loader, use_teacher=True):\n",
    "        # Use teacher model for evaluation (usually better)\n",
    "        model = self.teacher_model if use_teacher else self.student_model\n",
    "        model.eval()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_preds)\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def train(self, labeled_loader, unlabeled_loader, val_loader, num_epochs=100):\n",
    "        best_accuracy = 0.0\n",
    "        train_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Train for one epoch\n",
    "            train_loss, sup_loss, unsup_loss, train_acc = self.train_epoch(\n",
    "                labeled_loader, unlabeled_loader, epoch\n",
    "            )\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_loss, val_accuracy = self.evaluate(val_loader)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | \"\n",
    "                  f\"Sup Loss: {sup_loss:.4f} | \"\n",
    "                  f\"Unsup Loss: {unsup_loss:.4f} | \"\n",
    "                  f\"Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Val Acc: {val_accuracy*100:.2f}%\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'student_state_dict': self.student_model.state_dict(),\n",
    "                    'teacher_state_dict': self.teacher_model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'accuracy': val_accuracy,\n",
    "                }, 'best_model_safestudent.pth')\n",
    "                print(f\"New best model saved with accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        # Plot training progress\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses)\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(val_accuracies)\n",
    "        plt.title('Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_progress.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return best_accuracy, train_losses, val_accuracies\n",
    "    \n",
    "    def test(self, test_loader):\n",
    "        # Load best model\n",
    "        checkpoint = torch.load('best_model_safestudent.pth')\n",
    "        self.student_model.load_state_dict(checkpoint['student_state_dict'])\n",
    "        self.teacher_model.load_state_dict(checkpoint['teacher_state_dict'])\n",
    "        \n",
    "        # Evaluate on test set using teacher model\n",
    "        test_loss, test_accuracy = self.evaluate(test_loader, use_teacher=True)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        self.teacher_model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(test_loader, desc=\"Computing confusion matrix\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = self.teacher_model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(\n",
    "            all_targets, \n",
    "            all_preds, \n",
    "            target_names=[index_to_label[i] for i in range(self.num_classes)],\n",
    "            digits=3\n",
    "        )\n",
    "        print(\"Classification Report:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        sns.heatmap(\n",
    "            cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=[index_to_label[i] for i in range(self.num_classes)],\n",
    "            yticklabels=[index_to_label[i] for i in range(self.num_classes)]\n",
    "        )\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.show()\n",
    "        \n",
    "        return test_accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Safe Student trainer\n",
    "trainer = SafeStudent(\n",
    "    student_model=student_model,\n",
    "    teacher_model=teacher_model,\n",
    "    num_classes=len(labels),\n",
    "    alpha=0.99,  # EMA decay rate\n",
    "    temperature=0.5,  # Temperature for soft targets\n",
    "    lambda_consistency=1.0  # Weight for consistency loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01401bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting Safe Student training...\")\n",
    "num_epochs = 30  # Adjust as needed\n",
    "best_accuracy, train_losses, val_accuracies = trainer.train(\n",
    "    labeled_loader=labeled_loader,\n",
    "    unlabeled_loader=unlabeled_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "print(f\"Training completed. Best validation accuracy: {best_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_accuracy, test_report = trainer.test(test_loader)\n",
    "print(f\"Final test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
